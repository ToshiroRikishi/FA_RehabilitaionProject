import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
import datetime

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
file_path = '/home/user/HpProject/FA_full_data.xlsx'
db_uri = 'postgresql://fauser:rnimufargnkc@localhost:5433/fa_rgnkc_db'
base_table = 'fa_rgnkc_data'
map_table = 'fa_rgnkc_mapping'
BATCH_SIZE = 200  # —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è INSERT

# === –ß—Ç–µ–Ω–∏–µ Excel ===
try:
    df = pd.read_excel(file_path)
    print(f"–§–∞–π–ª –ø—Ä–æ—á–∏—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ. –°—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}, —Å—Ç—Ä–æ–∫: {len(df)}")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ Excel-—Ñ–∞–π–ª–∞: {e}")
    raise SystemExit(1)

original_columns = df.columns.tolist()

# === –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –∏–º–µ–Ω–∞ col_1, col_2, ... ===
new_columns = [f"col_{i+1}" for i in range(len(original_columns))]

# –ú–µ–Ω—è–µ–º –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö
df_renamed = df.copy()
df_renamed.columns = new_columns

print("\n‚úÖ –ö–æ–ª–æ–Ω–∫–∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω—ã (–ø–µ—Ä–≤—ã–µ 5):")
for i in range(min(5, len(new_columns))):
    print(f"  {new_columns[i]} ‚Üê {original_columns[i]}")

# === –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ SQL-—Ç–∏–ø–æ–≤ –ø–æ –¥–∞–Ω–Ω—ã–º ===
def get_sql_type(series: pd.Series) -> str:
    if pd.api.types.is_integer_dtype(series):
        return 'INTEGER'
    elif pd.api.types.is_float_dtype(series):
        return 'FLOAT'
    elif pd.api.types.is_datetime64_any_dtype(series):
        return 'DATE'  # –µ—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å –≤—Ä–µ–º—è ‚Äî –∑–∞–º–µ–Ω–∏ –Ω–∞ TIMESTAMP
    else:
        return 'TEXT'

col_sql_types = [get_sql_type(df_renamed[c]) for c in new_columns]

# === –°–æ–∑–¥–∞–Ω–∏–µ SQL DDL ===
data_columns_sql = [f'    "{col}" {col_sql_types[i]}' for i, col in enumerate(new_columns)]
create_data_sql = f"""
CREATE TABLE {base_table} (
{', '.join(data_columns_sql)}
);
"""

create_map_sql = f"""
CREATE TABLE {map_table} (
    name_base_table TEXT,
    full_name TEXT
);
"""

# === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–∞–ø–ø–∏–Ω–≥–∞ (–±–µ–∑ –∑–∞–º–µ–Ω—ã —Å–∏–º–≤–æ–ª–æ–≤) ===
mapping_records = [
    (new, str(orig)) # <--- –ò–ó–ú–ï–ù–ï–ù–ò–ï –ó–î–ï–°–¨: —É–±—Ä–∞–Ω–æ .replace('_', ' ')
    for new, orig in zip(new_columns, original_columns)
]

# === –§—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–¥ —Ç–∏–ø –¥–ª—è INSERT ===
def prepare_cell(value, sql_type):
    # NULL
    if pd.isna(value):
        return None

    if sql_type == 'DATE':
        # –ø—Ä–∏–≤–æ–¥–∏–º –∫ date
        if isinstance(value, pd.Timestamp):
            return value.date()
        if isinstance(value, datetime.datetime):
            return value.date()
        if isinstance(value, datetime.date):
            return value
        # –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å—Ç—Ä–æ–∫—É
        try:
            return pd.to_datetime(value, errors='coerce').date()
        except Exception:
            return None

    if sql_type == 'INTEGER':
        try:
            # –û—Å—Ç–æ—Ä–æ–∂–Ω–æ: float –≤–∏–¥–∞ 12.0 -> 12
            if isinstance(value, float) and value.is_integer():
                return int(value)
            return int(value)
        except Exception:
            return None

    if sql_type == 'FLOAT':
        try:
            return float(value)
        except Exception:
            return None

    # TEXT ‚Äî –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ –≤ —Å—Ç—Ä–æ–∫—É
    return str(value)

# === –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ INSERT –¥–ª—è –¥–∞–Ω–Ω—ã—Ö ===
columns_list_sql = ','.join([f'"{c}"' for c in new_columns])
insert_data_sql = f'INSERT INTO {base_table} ({columns_list_sql}) VALUES %s'

# === –†–∞–±–æ—Ç–∞ —Å –ë–î ===
try:
    conn = psycopg2.connect(db_uri)
    cur = conn.cursor()

    # –ü–µ—Ä–µc–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—ã
    cur.execute(f'DROP TABLE IF EXISTS {base_table};')
    cur.execute(f'DROP TABLE IF EXISTS {map_table};')
    cur.execute(create_data_sql)
    cur.execute(create_map_sql)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ø–ø–∏–Ω–≥
    execute_values(
        cur,
        f'INSERT INTO {map_table} (name_base_table, full_name) VALUES %s',
        mapping_records,
        page_size=1000
    )
    print(f"\nüìö –í {map_table} –¥–æ–±–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(mapping_records)}")

    # –ì–æ—Ç–æ–≤–∏–º –∏ –≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞–º–∏
    total_rows = 0
    batch = []
    for row in df_renamed.itertuples(index=False, name=None):
        prepared = [prepare_cell(row[j], col_sql_types[j]) for j in range(len(new_columns))]
        batch.append(tuple(prepared))
        if len(batch) >= BATCH_SIZE:
            execute_values(cur, insert_data_sql, batch, page_size=BATCH_SIZE)
            total_rows += len(batch)
            batch.clear()

    # –•–≤–æ—Å—Ç
    if batch:
        execute_values(cur, insert_data_sql, batch, page_size=BATCH_SIZE)
        total_rows += len(batch)
        batch.clear()

    conn.commit()
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {total_rows} —Å—Ç—Ä–æ–∫ –≤ {base_table}")

except Exception as e:
    if 'conn' in locals():
        conn.rollback()
    print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –ë–î: {e}")

finally:
    if 'cur' in locals():
        cur.close()
    if 'conn' in locals():
        conn.close()